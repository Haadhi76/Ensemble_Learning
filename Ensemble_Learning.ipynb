{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1585c66f",
   "metadata": {},
   "source": [
    "### The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf0dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec7a5f",
   "metadata": {},
   "source": [
    "### Hard Example Mining (HEM) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Example Mining (HEM) algorithm\n",
    "def hard_example_mining(clf, X_train, y_train, n_hard_examples):\n",
    "    w = X_train.shape[1]\n",
    "    y_pred = clf.predict(X_train).reshape(-1,1)\n",
    "    y_pred[y_pred==-1] = 0\n",
    "    errors = np.abs(y_train - y_pred)\n",
    "    hard_examples_idx = np.argsort(errors)[-n_hard_examples:]\n",
    "    return X_train[hard_examples_idx].reshape(-1,w), y_train[hard_examples_idx].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4d120",
   "metadata": {},
   "source": [
    "### Soft Example Mining (SEM) algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a997238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Example Mining (SEM) algorithm\n",
    "def soft_example_mining(clf, X_train, y_train, n_soft_examples):\n",
    "    w = X_train.shape[1]\n",
    "    y_proba = np.min(clf.predict_proba(X_train), axis=1).reshape(-1,1)\n",
    "    soft_examples_idx = np.argsort(np.abs(y_train - y_proba))[:n_soft_examples]\n",
    "    return X_train[soft_examples_idx].reshape(-1,w), y_train[soft_examples_idx].reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808b24e",
   "metadata": {},
   "source": [
    "### Balanced Cascade with Filters (BCWF) algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c224c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Cascade with Filters (BCWF) algorithm\n",
    "def bcwf(X, y, T, filter_type='hard', n_hard_examples=10, n_soft_examples=10):\n",
    "    w = X.shape[1]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "    classifiers = []\n",
    "    f = y_train.reshape(-1,1)\n",
    "    for i in range(w-1):\n",
    "        f = np.concatenate((f, y_train.reshape(-1,1)), axis=1)\n",
    "\n",
    "    n = np.sum(y_train==-1)\n",
    "    p = np.sum(y_train==1)\n",
    "\n",
    "    for t in range(T):\n",
    "        clf = AdaBoostClassifier(n_estimators=50)\n",
    "        clf.fit(X_train, y_train)\n",
    "        classifiers.append(clf)\n",
    "        NHE = X_train[f==-1].reshape(n,w)[np.argsort(np.max(clf.predict_proba(X_train[f==-1].reshape(n,w)), axis=1))]\n",
    "        PHE = X_train[f==1].reshape(p,w)[np.argsort(np.max(clf.predict_proba(X_train[f==1].reshape(p,w)), axis=1))[::-1]]\n",
    "        \n",
    "        n2 = int(np.ceil((n - p + PHE.shape[0]) / T))\n",
    "        n1 = int(np.ceil(NHE.shape[0] / T))\n",
    "        p1 = int(np.ceil(PHE.shape[0] / T))\n",
    "        \n",
    "        if filter_type == 'hard':\n",
    "            X_hard, y_hard = hard_example_mining(clf, X_train, y_train, n_hard_examples)\n",
    "            X_train = np.vstack((X_train, X_hard))\n",
    "            y_train = np.vstack((y_train.reshape(-1, 1), y_hard)).squeeze()\n",
    "\n",
    "        elif filter_type == 'soft':\n",
    "            X_soft, y_soft = soft_example_mining(clf, X_train, y_train, n_soft_examples)\n",
    "            X_train = np.vstack((X_train, X_soft))\n",
    "            y_train = np.vstack((y_train.reshape(-1, 1), y_soft)).squeeze()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown filter type. Please choose 'hard' or 'soft'\")\n",
    "\n",
    "        return classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7978d",
   "metadata": {},
   "source": [
    "### Ensemble voting strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble voting strategies\n",
    "def ensemble_predict(classifiers, X, strategy='majority_vote'):\n",
    "    \n",
    "    preds = []\n",
    "    for clf in classifiers:\n",
    "        if strategy == 'majority_vote':\n",
    "            pred = clf.predict(X)\n",
    "        elif strategy == 'average_probability':\n",
    "            pred = clf.predict_proba(X)[:, 1]  # probability of positive class\n",
    "        else:\n",
    "            raise ValueError(\"Invalid prediction strategy: %s\" % strategy)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    preds = np.asarray(preds) \n",
    "    preds = np.squeeze(preds)\n",
    "    preds = np.where(preds == -1, 0, preds)\n",
    "    if strategy == 'majority_vote':\n",
    "        preds = np.ravel(preds)  # flatten the input array\n",
    "        k = np.argmax(np.bincount(preds))\n",
    "    elif strategy == 'average_probability':\n",
    "        k = np.mean(preds, axis=0)\n",
    "    preds[preds == 0] = -1\n",
    "    return preds.reshape(-1,1), k\n",
    "\n",
    "# To calculate the accuracy\n",
    "def accuracy(preds,y_test):\n",
    "    return (preds == y_test).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a902ed1",
   "metadata": {},
   "source": [
    "### Loading the Data from the data set CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e42ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_train = pd.read_csv('train_hou.csv')\n",
    "df_test = pd.read_csv('test_hou.csv')\n",
    "\n",
    "# Setting up train and test set\n",
    "X_train,y_train = np.array(df_train[df_train.columns[:df_train.shape[1]-1]]), np.array(df_train[['TARGET']]).astype(int)\n",
    "X_test,y_test = np.array(df_test[df_test.columns[:df_test.shape[1]-1]]), np.array(df_test[['TARGET']]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d0c94",
   "metadata": {},
   "source": [
    "### Evaluate the algorithms on benchmark datasets and a real-world peer-to-peer lending dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3526fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the algorithms on benchmark datasets and a real-world peer-to-peer lending dataset\n",
    "# Ploting\n",
    "max_T = 50\n",
    "classifiers_hard = []\n",
    "classifiers_soft = []\n",
    "p_hard_all = []\n",
    "p_soft_all = []\n",
    "k_hard_mv = []\n",
    "k_hard_ap = []\n",
    "k_soft_mv = []\n",
    "k_soft_ap = []\n",
    "accuracy_hard = []\n",
    "accuracy_soft = []\n",
    "\n",
    "for T in range(1, max_T+1):\n",
    "    classifiers_hard_t = bcwf(X_train, y_train, T=T, filter_type='hard', n_hard_examples=100, n_soft_examples=100)\n",
    "    classifiers_soft_t = bcwf(X_train, y_train, T=T, filter_type='soft', n_hard_examples=100, n_soft_examples=100)\n",
    "    p_hard_t_mv, k_hard_mv_t = ensemble_predict(classifiers_hard_t, X_test, strategy='majority_vote')\n",
    "    p_soft_t_mv, k_soft_mv_t = ensemble_predict(classifiers_soft_t, X_test, strategy='majority_vote')\n",
    "    p_hard_t_ap, k_hard_ap_t = ensemble_predict(classifiers_hard_t, X_test, strategy='average_probability')\n",
    "    p_soft_t_ap, k_soft_ap_t = ensemble_predict(classifiers_soft_t, X_test, strategy='average_probability')\n",
    "    accuracy_hard_t = accuracy(p_hard_t_mv, y_test)\n",
    "    accuracy_soft_t = accuracy(p_soft_t_mv, y_test)\n",
    "    classifiers_hard.append(classifiers_hard_t)\n",
    "    classifiers_soft.append(classifiers_soft_t)\n",
    "    p_hard_all.append(p_hard_t_mv)\n",
    "    p_soft_all.append(p_soft_t_mv)\n",
    "    k_hard_mv.append(k_hard_mv_t)\n",
    "    k_soft_mv.append(k_soft_mv_t)\n",
    "    k_hard_ap.append(k_hard_ap_t)\n",
    "    k_soft_ap.append(k_soft_ap_t)\n",
    "    accuracy_hard.append(accuracy_hard_t)\n",
    "    accuracy_soft.append(accuracy_soft_t)\n",
    "\n",
    "    # Get the indices of correct, wrong, and normal predictions for the hard filter\n",
    "    correct_hard_idx = np.where(np.round(p_hard_t_ap) == y_test)[0]\n",
    "    wrong_hard_idx = np.where(np.round(p_hard_t_ap) != y_test)[0]\n",
    "    normal_hard_idx = np.where(np.abs(np.round(p_hard_t_ap) - y_test) > 1)[0]\n",
    "\n",
    "    # Get the indices of correct, wrong, and normal predictions for the soft filter\n",
    "    correct_soft_idx = np.where(np.round(p_soft_t_ap) == y_test)[0]\n",
    "    wrong_soft_idx = np.where(np.round(p_soft_t_ap) != y_test)[0]\n",
    "    normal_soft_idx = np.where(np.abs(np.round(p_soft_t_ap) - y_test) > 1)[0]\n",
    "    if T == max_T:\n",
    "        # Scatter plot - Hard Filter\n",
    "        plt.scatter(y_test[correct_hard_idx], p_hard_t_ap[correct_hard_idx], c='g', label='Correct Predictions - Hard')\n",
    "        plt.scatter(y_test[wrong_hard_idx], p_hard_t_ap[wrong_hard_idx], c='r', label='Wrong Predictions - Hard')\n",
    "        plt.scatter(y_test[normal_hard_idx], p_hard_t_ap[normal_hard_idx], c='b', label='Normal Predictions - Hard')\n",
    "        plt.xlabel(\"True Values\")\n",
    "        plt.ylabel(\"Predictions\")\n",
    "        plt.title(\"Scatter plot for Hard Filter Predictions (T=50)\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Scatter plot - Soft Filter\n",
    "        plt.scatter(y_test[correct_soft_idx], p_soft_t_ap[correct_soft_idx], marker='s', c='y', label='Correct Predictions - Soft')\n",
    "        plt.scatter(y_test[wrong_soft_idx], p_soft_t_ap[wrong_soft_idx], marker='s', c='m', label='Wrong Predictions - Soft')\n",
    "        plt.scatter(y_test[normal_soft_idx], p_soft_t_ap[normal_soft_idx], marker='s', c='c', label='Normal Predictions - Soft')\n",
    "        plt.xlabel(\"True Values\")\n",
    "        plt.ylabel(\"Predictions\")\n",
    "        plt.title(\"Scatter plot for Soft Filter Predictions (T=50)\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de231c2c",
   "metadata": {},
   "source": [
    "## Making the graphs for different parameters\n",
    "### The output graphs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1beaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rest of the plots\n",
    "# Plot accuracy vs T\n",
    "plt.scatter(range(1, max_T+1), accuracy_hard, label='Hard Filter')\n",
    "plt.scatter(range(1, max_T+1), accuracy_soft, label='Soft Filter')\n",
    "plt.xlabel(\"T (Number of Iterations)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Scatter plot of Accuracy vs T\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot k vs T for hard filter\n",
    "plt.plot(range(1, max_T+1), k_hard_mv, label='Hard Filter Majority Vote')\n",
    "plt.plot(range(1, max_T+1), k_hard_ap, label='Hard Filter Average Probability')\n",
    "plt.xlabel(\"T (Number of Iterations)\")\n",
    "plt.ylabel(\"k (Number of Examples Filtered)\")\n",
    "plt.title(\"k vs T for Hard Filter\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot k vs T for soft filter\n",
    "plt.plot(range(1, max_T+1), k_soft_mv, label='Soft Filter Majority Vote')\n",
    "plt.plot(range(1, max_T+1), k_soft_ap, label='Soft Filter Average Probability')\n",
    "plt.xlabel(\"T (Number of Iterations)\")\n",
    "plt.ylabel(\"k (Number of Examples Filtered)\")\n",
    "plt.title(\"k vs T for Soft Filter\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
